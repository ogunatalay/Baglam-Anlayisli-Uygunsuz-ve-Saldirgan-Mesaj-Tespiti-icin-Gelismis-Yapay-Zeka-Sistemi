# -*- coding: utf-8 -*-
"""DDİ PROJESİ.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1egbARnEPFagC5QS_p_W2KfZ3MhaWomqB
"""



import pandas as pd

# Dosyayı oku
df = pd.read_csv("labeled_data.csv")

# Sadece tweet ve class sütunlarını al
df = df[['tweet', 'class']]

# İlk 5 satırı görelim
df.head()

import re
import nltk
import pandas as pd
from nltk.corpus import stopwords

# İlk kez çalıştırıyorsan aşağıdakileri indir
nltk.download('stopwords')

# Türkçe ve İngilizce stopword'leri birleştir
stop_words = set(stopwords.words('english')).union(set(stopwords.words('turkish')))

def clean_text(text):
    text = text.lower()  # Küçük harfe çevir
    text = re.sub(r"http\S+", "", text)  # Linkleri sil
    text = re.sub(r"@\w+", "", text)  # Mentionları sil
    text = re.sub(r"#\w+", "", text)  # Hashtagleri sil
    text = re.sub(r"[^\w\s]", "", text)  # Noktalama işaretlerini sil
    text = re.sub(r"\d+", "", text)  # Sayıları sil
    text = re.sub(r"\s+", " ", text).strip()  # Fazla boşlukları temizle
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]  # Stopword'leri çıkar
    return " ".join(tokens)

df['CLEAN_TEXT'] = df['tweet'].apply(clean_text)

# İlk 5 satırı görelim
df[['tweet', 'CLEAN_TEXT', 'class']].head()

df.to_csv("cleaned_labeled_data.csv", index=False)

from google.colab import files
files.download("cleaned_labeled_data.csv")

!pip install wordcloud
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Sınıf adlarını daha anlamlı hale getirelim
class_labels = {
    0: "Hate Speech",
    1: "Offensive Language",
    2: "Neither"
}

# WordCloud çizimi için fonksiyon
def plot_wordcloud(data, title):
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(" ".join(data))
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(title, fontsize=18)
    plt.axis('off')
    plt.tight_layout()
    plt.show()

# Her sınıf için ayrı ayrı word cloud çizelim
for class_id, label in class_labels.items():
    class_data = df[df['class'] == class_id]['CLEAN_TEXT']
    plot_wordcloud(class_data, f"WordCloud - {label}")

from sklearn.model_selection import train_test_split
# Özellik ve etiketleri belirle
X = df['CLEAN_TEXT']  # Girdi olarak temiz metinler
y = df['class']       # Hedef sınıflar (0, 1, 2)

# Eğitim ve test olarak ayır (örnek: %80 eğitim, %20 test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Boyutlara bakalım
print("Eğitim verisi:", len(X_train))
print("Test verisi  :", len(X_test))

# Her sınıftaki örnek sayısı
class_counts = df['class'].value_counts().sort_index()
print(class_counts)
# Sınıf adlarıyla etiketleme
class_labels = {
    0: "Hate Speech",
    1: "Offensive Language",
    2: "Neither"
}

# Sınıf adlarını etiketleyerek göster
for cls_id, count in class_counts.items():
    print(f"{class_labels[cls_id]}: {count} tweet")
import matplotlib.pyplot as plt

# Grafik çizimi
plt.figure(figsize=(8, 5))
plt.bar(class_counts.index.map(class_labels), class_counts.values, color=["#e74c3c", "#f1c40f", "#2ecc71"])
plt.title("Her Sınıf için Veri Sayısı", fontsize=16)
plt.xlabel("Sınıf", fontsize=12)
plt.ylabel("Veri Sayısı", fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Örnek olarak tweet dizilimini bağlamsal hale getiriyoruz
context_inputs = []
previous_texts = df['CLEAN_TEXT'].tolist()

for i in range(len(previous_texts)):
    if i == 0:
        context_inputs.append(previous_texts[i])
    else:
        combined = previous_texts[i-1] + " [SEP] " + previous_texts[i]
        context_inputs.append(combined)

# Yeni sütun ekle
df['CONTEXT_INPUT'] = context_inputs

# İlk 5 örneği görelim
df[['CONTEXT_INPUT', 'class']].head()

# context_input içeren veri setini kaydet
df.to_csv("context_aware_labeled_data.csv", index=False)

from google.colab import files
files.download("context_aware_labeled_data.csv")

!pip install --upgrade transformers

# ✅ Gerekli Kurulumlar
!pip install --upgrade transformers datasets --quiet

# ✅ GPU kontrolü
import torch
print("GPU kullanılabilir mi?", torch.cuda.is_available())

# ✅ Gerekli kütüphaneler
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from torch.utils.data import Dataset

# ✅ 1. Veri Yükleme
df = pd.read_csv("context_aware_labeled_data.csv")

# ✅ 2. Özellik ve etiket
X = df['CONTEXT_INPUT'].tolist()
y = df['class'].tolist()

# ✅ 3. Train/Test split (%80 - %20)
X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# ✅ 4. Train/Validation split (%90 - %10)
X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, stratify=y_train_full, random_state=42)

# ✅ 5. Tokenizer
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# ✅ 6. Dataset sınıfı
class TweetDataset(Dataset):
    def __init__(self, texts, labels):
        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

# ✅ 7. Dataset’leri oluştur
train_dataset = TweetDataset(X_train, y_train)
val_dataset   = TweetDataset(X_val, y_val)
test_dataset  = TweetDataset(X_test, y_test)

# ✅ 8. Modeli yükle
model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)

# ✅ 9. Eğitim ayarları
training_args = TrainingArguments(
    output_dir="./results",
    logging_strategy="epoch",  # `evaluation_strategy` yerine `logging_strategy` kullanabilirsiniz
    save_strategy="no",
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=50,
    report_to="none"
)


# ✅ 10. Trainer nesnesi
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

# ✅ 11. Eğitimi başlat
trainer.train()

# ✅ 12. Train seti üzerinde tahmin yap
train_preds_output = trainer.predict(train_dataset)
train_preds = torch.argmax(torch.tensor(train_preds_output.predictions), axis=1)
train_labels = torch.tensor(train_preds_output.label_ids)

# ✅ 13. Test seti üzerinde tahmin yap
test_preds_output = trainer.predict(test_dataset)
test_preds = torch.argmax(torch.tensor(test_preds_output.predictions), axis=1)
test_labels = torch.tensor(test_preds_output.label_ids)

class_names = ["Hate Speech", "Offensive", "Neither"]

# ✅ 14. Sınıflandırma Raporu (Classification Report)
print("\n📊 TRAIN Sınıflandırma Raporu:")
print(classification_report(train_labels, train_preds, target_names=class_names))

print("\n📊 TEST Sınıflandırma Raporu:")
print(classification_report(test_labels, test_preds, target_names=class_names))

# ✅ 15. Confusion Matrix (Train ve Test Setleri)
# Train CM
cm_train = confusion_matrix(train_labels, train_preds)
disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=class_names)
fig, ax = plt.subplots(figsize=(6, 6))
disp_train.plot(cmap="Greens", ax=ax, values_format='d')
plt.title("Confusion Matrix – TRAIN Seti")
plt.show()

# Test CM
cm_test = confusion_matrix(test_labels, test_preds)
disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=class_names)
fig, ax = plt.subplots(figsize=(6, 6))
disp_test.plot(cmap="Blues", ax=ax, values_format='d')
plt.title("Confusion Matrix – TEST Seti")
plt.show()

# ✅ 16. Loss Grafiklerini Çiz (Train ve Validation)
logs = trainer.state.log_history

train_loss = [log["loss"] for log in logs if "loss" in log]
eval_loss = [log["eval_loss"] for log in logs if "eval_loss" in log]

plt.figure(figsize=(10, 4))
plt.plot(train_loss, label="Train Loss")
plt.plot(eval_loss, label="Validation Loss")
plt.title("Eğitim ve Validation Kayıp Grafiği")
plt.xlabel("Adım")
plt.ylabel("Loss")
plt.legend()
plt.grid()
plt.show()

# Eğitim sonrasında modeli kaydet
trainer.save_model("./results")

from transformers import TrainingArguments, Trainer

# Eğitim ayarlarını güncelle
training_args = TrainingArguments(
    output_dir="./results",
    logging_strategy="epoch",
    save_strategy="epoch",  # Modeli her epoch sonunda kaydet
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=50,
    report_to="none",
    save_total_limit=2,  # En fazla 2 model kaydını tut
)

# Trainer'ı tekrar oluştur
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

# Eğitimi başlat
trainer.train()

# Modeli kaydet
trainer.save_model("./results")

# Modeli yükle
model = BertForSequenceClassification.from_pretrained("./results", num_labels=3)

from transformers import BertTokenizer, BertForSequenceClassification
import torch

# Model ve tokenizer'ı yükle
model_path = "./results"  # Eğitilen modelin kaydedildiği dizin
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertForSequenceClassification.from_pretrained(model_path)

# Sınıf isimleri
class_names = ["Hate Speech", "Offensive", "Neither"]

def classify_text(text):
    """
    Verilen metni sınıflandırır ve detaylı sonuç döndürür.

    Args:
        text (str): Analiz edilecek metin

    Returns:
        dict: {
            'prediction': str (tahmin edilen sınıf),
            'confidence': float (tahmin güven skoru),
            'probabilities': dict (tüm sınıfların olasılıkları),
            'raw_output': list (modelin ham çıktıları)
        }
    """
    # Tokenization
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=128
    )

    # Model ile tahmin yap
    with torch.no_grad():
        outputs = model(**inputs)

    # Olasılıkları hesapla
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    confidence, predicted_idx = torch.max(probs, dim=-1)

    # Sonuçları formatla
    result = {
        'prediction': class_names[predicted_idx],
        'confidence': confidence.item(),
        'probabilities': {
            class_names[i]: round(probs[0][i].item(), 4) for i in range(len(class_names))
        },
        'raw_output': outputs.logits.tolist()[0]
    }

    return result

# Kullanım örnekleri
sample_texts = [
    "I love this place! The staff is amazing!",
    "You're so stupid, I can't believe you did that",
    "All people from that country should be killed"
]

for text in sample_texts:
    print(f"\nMetin: '{text}'")
    result = classify_text(text)
    print(f"Tahmin: {result['prediction']} (%{result['confidence']*100:.2f})")
    print("Detaylar:")
    for cls, prob in result['probabilities'].items():
        print(f"  {cls}: {prob*100:.2f}%")
    print("---")



import pandas as pd

# Dosyayı oku
df = pd.read_csv("labeled_data.csv")

# Sadece tweet ve class sütunlarını al
df = df[['tweet', 'class']]

# İlk 5 satırı görelim
df.head()

import re
import nltk
import pandas as pd
from nltk.corpus import stopwords

# İlk kez çalıştırıyorsan aşağıdakileri indir
nltk.download('stopwords')

# Türkçe ve İngilizce stopword'leri birleştir
stop_words = set(stopwords.words('english')).union(set(stopwords.words('turkish')))

def clean_text(text):
    text = text.lower()  # Küçük harfe çevir
    text = re.sub(r"http\S+", "", text)  # Linkleri sil
    text = re.sub(r"@\w+", "", text)  # Mentionları sil
    text = re.sub(r"#\w+", "", text)  # Hashtagleri sil
    text = re.sub(r"[^\w\s]", "", text)  # Noktalama işaretlerini sil
    text = re.sub(r"\d+", "", text)  # Sayıları sil
    text = re.sub(r"\s+", " ", text).strip()  # Fazla boşlukları temizle
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]  # Stopword'leri çıkar
    return " ".join(tokens)

df['CLEAN_TEXT'] = df['tweet'].apply(clean_text)

# İlk 5 satırı görelim
df[['tweet', 'CLEAN_TEXT', 'class']].head()

df.to_csv("cleaned_labeled_data.csv", index=False)

from google.colab import files
files.download("cleaned_labeled_data.csv")

!pip install wordcloud
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Sınıf adlarını daha anlamlı hale getirelim
class_labels = {
    0: "Hate Speech",
    1: "Offensive Language",
    2: "Neither"
}

# WordCloud çizimi için fonksiyon
def plot_wordcloud(data, title):
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(" ".join(data))
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(title, fontsize=18)
    plt.axis('off')
    plt.tight_layout()
    plt.show()

# Her sınıf için ayrı ayrı word cloud çizelim
for class_id, label in class_labels.items():
    class_data = df[df['class'] == class_id]['CLEAN_TEXT']
    plot_wordcloud(class_data, f"WordCloud - {label}")

from sklearn.model_selection import train_test_split
# Özellik ve etiketleri belirle
X = df['CLEAN_TEXT']  # Girdi olarak temiz metinler
y = df['class']       # Hedef sınıflar (0, 1, 2)

# Eğitim ve test olarak ayır (örnek: %80 eğitim, %20 test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Boyutlara bakalım
print("Eğitim verisi:", len(X_train))
print("Test verisi  :", len(X_test))

# Her sınıftaki örnek sayısı
class_counts = df['class'].value_counts().sort_index()
print(class_counts)
# Sınıf adlarıyla etiketleme
class_labels = {
    0: "Hate Speech",
    1: "Offensive Language",
    2: "Neither"
}

# Sınıf adlarını etiketleyerek göster
for cls_id, count in class_counts.items():
    print(f"{class_labels[cls_id]}: {count} tweet")
import matplotlib.pyplot as plt

# Grafik çizimi
plt.figure(figsize=(8, 5))
plt.bar(class_counts.index.map(class_labels), class_counts.values, color=["#e74c3c", "#f1c40f", "#2ecc71"])
plt.title("Her Sınıf için Veri Sayısı", fontsize=16)
plt.xlabel("Sınıf", fontsize=12)
plt.ylabel("Veri Sayısı", fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Örnek olarak tweet dizilimini bağlamsal hale getiriyoruz
context_inputs = []
previous_texts = df['CLEAN_TEXT'].tolist()

for i in range(len(previous_texts)):
    if i == 0:
        context_inputs.append(previous_texts[i])
    else:
        combined = previous_texts[i-1] + " [SEP] " + previous_texts[i]
        context_inputs.append(combined)

# Yeni sütun ekle
df['CONTEXT_INPUT'] = context_inputs

# İlk 5 örneği görelim
df[['CONTEXT_INPUT', 'class']].head()

# context_input içeren veri setini kaydet
df.to_csv("context_aware_labeled_data.csv", index=False)

from google.colab import files
files.download("context_aware_labeled_data.csv")

!pip install --upgrade transformers

# ✅ Gerekli Kurulumlar
!pip install --upgrade transformers datasets --quiet

# ✅ GPU kontrolü
import torch
print("GPU kullanılabilir mi?", torch.cuda.is_available())

# ✅ Gerekli kütüphaneler
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from torch.utils.data import Dataset

# ✅ 1. Veri Yükleme
df = pd.read_csv("context_aware_labeled_data.csv")

# ✅ 2. Özellik ve etiket
X = df['CONTEXT_INPUT'].tolist()
y = df['class'].tolist()

# ✅ 3. Train/Test split (%80 - %20)
X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# ✅ 4. Train/Validation split (%90 - %10)
X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, stratify=y_train_full, random_state=42)

# ✅ 5. Tokenizer
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# ✅ 6. Dataset sınıfı
class TweetDataset(Dataset):
    def __init__(self, texts, labels):
        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

# ✅ 7. Dataset’leri oluştur
train_dataset = TweetDataset(X_train, y_train)
val_dataset   = TweetDataset(X_val, y_val)
test_dataset  = TweetDataset(X_test, y_test)

# ✅ 8. Modeli yükle
model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)

# ✅ 9. Eğitim ayarları
training_args = TrainingArguments(
    output_dir="./results",
    logging_strategy="epoch",  # `evaluation_strategy` yerine `logging_strategy` kullanabilirsiniz
    save_strategy="no",
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=50,
    report_to="none"
)


# ✅ 10. Trainer nesnesi
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

# ✅ 11. Eğitimi başlat
trainer.train()

# ✅ 12. Train seti üzerinde tahmin yap
train_preds_output = trainer.predict(train_dataset)
train_preds = torch.argmax(torch.tensor(train_preds_output.predictions), axis=1)
train_labels = torch.tensor(train_preds_output.label_ids)

# ✅ 13. Test seti üzerinde tahmin yap
test_preds_output = trainer.predict(test_dataset)
test_preds = torch.argmax(torch.tensor(test_preds_output.predictions), axis=1)
test_labels = torch.tensor(test_preds_output.label_ids)

class_names = ["Hate Speech", "Offensive", "Neither"]

# ✅ 14. Sınıflandırma Raporu (Classification Report)
print("\n📊 TRAIN Sınıflandırma Raporu:")
print(classification_report(train_labels, train_preds, target_names=class_names))

print("\n📊 TEST Sınıflandırma Raporu:")
print(classification_report(test_labels, test_preds, target_names=class_names))

# ✅ 15. Confusion Matrix (Train ve Test Setleri)
# Train CM
cm_train = confusion_matrix(train_labels, train_preds)
disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=class_names)
fig, ax = plt.subplots(figsize=(6, 6))
disp_train.plot(cmap="Greens", ax=ax, values_format='d')
plt.title("Confusion Matrix – TRAIN Seti")
plt.show()

# Test CM
cm_test = confusion_matrix(test_labels, test_preds)
disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=class_names)
fig, ax = plt.subplots(figsize=(6, 6))
disp_test.plot(cmap="Blues", ax=ax, values_format='d')
plt.title("Confusion Matrix – TEST Seti")
plt.show()

# ✅ 16. Loss Grafiklerini Çiz (Train ve Validation)
logs = trainer.state.log_history

train_loss = [log["loss"] for log in logs if "loss" in log]
eval_loss = [log["eval_loss"] for log in logs if "eval_loss" in log]

plt.figure(figsize=(10, 4))
plt.plot(train_loss, label="Train Loss")
plt.plot(eval_loss, label="Validation Loss")
plt.title("Eğitim ve Validation Kayıp Grafiği")
plt.xlabel("Adım")
plt.ylabel("Loss")
plt.legend()
plt.grid()
plt.show()

# Eğitim sonrasında modeli kaydet
trainer.save_model("./results")

from transformers import TrainingArguments, Trainer

# Eğitim ayarlarını güncelle
training_args = TrainingArguments(
    output_dir="./results",
    logging_strategy="epoch",
    save_strategy="epoch",  # Modeli her epoch sonunda kaydet
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=50,
    report_to="none",
    save_total_limit=2,  # En fazla 2 model kaydını tut
)

# Trainer'ı tekrar oluştur
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

# Eğitimi başlat
trainer.train()

# Modeli kaydet
trainer.save_model("./results")

# Modeli yükle
model = BertForSequenceClassification.from_pretrained("./results", num_labels=3)

from transformers import BertTokenizer, BertForSequenceClassification
import torch

# Model ve tokenizer'ı yükle
model_path = "./results"  # Eğitilen modelin kaydedildiği dizin
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertForSequenceClassification.from_pretrained(model_path)

# Sınıf isimleri
class_names = ["Hate Speech", "Offensive", "Neither"]

def classify_text(text):
    """
    Verilen metni sınıflandırır ve detaylı sonuç döndürür.

    Args:
        text (str): Analiz edilecek metin

    Returns:
        dict: {
            'prediction': str (tahmin edilen sınıf),
            'confidence': float (tahmin güven skoru),
            'probabilities': dict (tüm sınıfların olasılıkları),
            'raw_output': list (modelin ham çıktıları)
        }
    """
    # Tokenization
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=128
    )

    # Model ile tahmin yap
    with torch.no_grad():
        outputs = model(**inputs)

    # Olasılıkları hesapla
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    confidence, predicted_idx = torch.max(probs, dim=-1)

    # Sonuçları formatla
    result = {
        'prediction': class_names[predicted_idx],
        'confidence': confidence.item(),
        'probabilities': {
            class_names[i]: round(probs[0][i].item(), 4) for i in range(len(class_names))
        },
        'raw_output': outputs.logits.tolist()[0]
    }

    return result

# Kullanım örnekleri
sample_texts = [
    "I love this place! The staff is amazing!",
    "You're so stupid, I can't believe you did that",
    "All people from that country should be killed"
]

for text in sample_texts:
    print(f"\nMetin: '{text}'")
    result = classify_text(text)
    print(f"Tahmin: {result['prediction']} (%{result['confidence']*100:.2f})")
    print("Detaylar:")
    for cls, prob in result['probabilities'].items():
        print(f"  {cls}: {prob*100:.2f}%")
    print("---")

import torch
print(torch.__version__)
print("CUDA mevcut mu?", torch.cuda.is_available())

!pip install -U transformers

import os
os.kill(os.getpid(), 9)



import pandas as pd

# Dosyayı oku
df = pd.read_csv("labeled_data.csv")

# Sadece tweet ve class sütunlarını al
df = df[['tweet', 'class']]

# İlk 5 satırı görelim
df.head()

import re
import nltk
import pandas as pd
from nltk.corpus import stopwords

# İlk kez çalıştırıyorsan aşağıdakileri indir
nltk.download('stopwords')

# Türkçe ve İngilizce stopword'leri birleştir
stop_words = set(stopwords.words('english')).union(set(stopwords.words('turkish')))

def clean_text(text):
    text = text.lower()  # Küçük harfe çevir
    text = re.sub(r"http\S+", "", text)  # Linkleri sil
    text = re.sub(r"@\w+", "", text)  # Mentionları sil
    text = re.sub(r"#\w+", "", text)  # Hashtagleri sil
    text = re.sub(r"[^\w\s]", "", text)  # Noktalama işaretlerini sil
    text = re.sub(r"\d+", "", text)  # Sayıları sil
    text = re.sub(r"\s+", " ", text).strip()  # Fazla boşlukları temizle
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]  # Stopword'leri çıkar
    return " ".join(tokens)

df['CLEAN_TEXT'] = df['tweet'].apply(clean_text)

# İlk 5 satırı görelim
df[['tweet', 'CLEAN_TEXT', 'class']].head()

df.to_csv("cleaned_labeled_data.csv", index=False)

from google.colab import files
files.download("cleaned_labeled_data.csv")

!pip install wordcloud
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Sınıf adlarını daha anlamlı hale getirelim
class_labels = {
    0: "Hate Speech",
    1: "Offensive Language",
    2: "Neither"
}

# WordCloud çizimi için fonksiyon
def plot_wordcloud(data, title):
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(" ".join(data))
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(title, fontsize=18)
    plt.axis('off')
    plt.tight_layout()
    plt.show()

# Her sınıf için ayrı ayrı word cloud çizelim
for class_id, label in class_labels.items():
    class_data = df[df['class'] == class_id]['CLEAN_TEXT']
    plot_wordcloud(class_data, f"WordCloud - {label}")

from sklearn.model_selection import train_test_split
# Özellik ve etiketleri belirle
X = df['CLEAN_TEXT']  # Girdi olarak temiz metinler
y = df['class']       # Hedef sınıflar (0, 1, 2)

# Eğitim ve test olarak ayır (örnek: %80 eğitim, %20 test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Boyutlara bakalım
print("Eğitim verisi:", len(X_train))
print("Test verisi  :", len(X_test))

# Her sınıftaki örnek sayısı
class_counts = df['class'].value_counts().sort_index()
print(class_counts)
# Sınıf adlarıyla etiketleme
class_labels = {
    0: "Hate Speech",
    1: "Offensive Language",
    2: "Neither"
}

# Sınıf adlarını etiketleyerek göster
for cls_id, count in class_counts.items():
    print(f"{class_labels[cls_id]}: {count} tweet")
import matplotlib.pyplot as plt

# Grafik çizimi
plt.figure(figsize=(8, 5))
plt.bar(class_counts.index.map(class_labels), class_counts.values, color=["#e74c3c", "#f1c40f", "#2ecc71"])
plt.title("Her Sınıf için Veri Sayısı", fontsize=16)
plt.xlabel("Sınıf", fontsize=12)
plt.ylabel("Veri Sayısı", fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Örnek olarak tweet dizilimini bağlamsal hale getiriyoruz
context_inputs = []
previous_texts = df['CLEAN_TEXT'].tolist()

for i in range(len(previous_texts)):
    if i == 0:
        context_inputs.append(previous_texts[i])
    else:
        combined = previous_texts[i-1] + " [SEP] " + previous_texts[i]
        context_inputs.append(combined)

# Yeni sütun ekle
df['CONTEXT_INPUT'] = context_inputs

# İlk 5 örneği görelim
df[['CONTEXT_INPUT', 'class']].head()

# context_input içeren veri setini kaydet
df.to_csv("context_aware_labeled_data.csv", index=False)

from google.colab import files
files.download("context_aware_labeled_data.csv")

!pip install --upgrade transformers

# ✅ Gerekli Kurulumlar
!pip install --upgrade transformers datasets --quiet

# ✅ GPU kontrolü
import torch
print("GPU kullanılabilir mi?", torch.cuda.is_available())

# ✅ Gerekli kütüphaneler
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from torch.utils.data import Dataset

# ✅ 1. Veri Yükleme
df = pd.read_csv("context_aware_labeled_data.csv")

# ✅ 2. Özellik ve etiket
X = df['CONTEXT_INPUT'].tolist()
y = df['class'].tolist()

# ✅ 3. Train/Test split (%80 - %20)
X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# ✅ 4. Train/Validation split (%90 - %10)
X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, stratify=y_train_full, random_state=42)

# ✅ 5. Tokenizer
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# ✅ 6. Dataset sınıfı
class TweetDataset(Dataset):
    def __init__(self, texts, labels):
        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

# ✅ 7. Dataset’leri oluştur
train_dataset = TweetDataset(X_train, y_train)
val_dataset   = TweetDataset(X_val, y_val)
test_dataset  = TweetDataset(X_test, y_test)

# ✅ 8. Modeli yükle
model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)

# ✅ 9. Eğitim ayarları
training_args = TrainingArguments(
    output_dir="./results",
    logging_strategy="epoch",  # `evaluation_strategy` yerine `logging_strategy` kullanabilirsiniz
    save_strategy="no",
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=50,
    report_to="none"
)


# ✅ 10. Trainer nesnesi
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

# ✅ 11. Eğitimi başlat
trainer.train()

# ✅ 12. Train seti üzerinde tahmin yap
train_preds_output = trainer.predict(train_dataset)
train_preds = torch.argmax(torch.tensor(train_preds_output.predictions), axis=1)
train_labels = torch.tensor(train_preds_output.label_ids)

# ✅ 13. Test seti üzerinde tahmin yap
test_preds_output = trainer.predict(test_dataset)
test_preds = torch.argmax(torch.tensor(test_preds_output.predictions), axis=1)
test_labels = torch.tensor(test_preds_output.label_ids)

class_names = ["Hate Speech", "Offensive", "Neither"]

# ✅ 14. Sınıflandırma Raporu (Classification Report)
print("\n📊 TRAIN Sınıflandırma Raporu:")
print(classification_report(train_labels, train_preds, target_names=class_names))

print("\n📊 TEST Sınıflandırma Raporu:")
print(classification_report(test_labels, test_preds, target_names=class_names))

# ✅ 15. Confusion Matrix (Train ve Test Setleri)
# Train CM
cm_train = confusion_matrix(train_labels, train_preds)
disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=class_names)
fig, ax = plt.subplots(figsize=(6, 6))
disp_train.plot(cmap="Greens", ax=ax, values_format='d')
plt.title("Confusion Matrix – TRAIN Seti")
plt.show()

# Test CM
cm_test = confusion_matrix(test_labels, test_preds)
disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=class_names)
fig, ax = plt.subplots(figsize=(6, 6))
disp_test.plot(cmap="Blues", ax=ax, values_format='d')
plt.title("Confusion Matrix – TEST Seti")
plt.show()

# ✅ 16. Loss Grafiklerini Çiz (Train ve Validation)
logs = trainer.state.log_history

train_loss = [log["loss"] for log in logs if "loss" in log]
eval_loss = [log["eval_loss"] for log in logs if "eval_loss" in log]

plt.figure(figsize=(10, 4))
plt.plot(train_loss, label="Train Loss")
plt.plot(eval_loss, label="Validation Loss")
plt.title("Eğitim ve Validation Kayıp Grafiği")
plt.xlabel("Adım")
plt.ylabel("Loss")
plt.legend()
plt.grid()
plt.show()

# Eğitim sonrasında modeli kaydet
trainer.save_model("./results")

from transformers import TrainingArguments, Trainer

# Eğitim ayarlarını güncelle
training_args = TrainingArguments(
    output_dir="./results",
    logging_strategy="epoch",
    save_strategy="epoch",  # Modeli her epoch sonunda kaydet
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=50,
    report_to="none",
    save_total_limit=2,  # En fazla 2 model kaydını tut
)

# Trainer'ı tekrar oluştur
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

# Eğitimi başlat
trainer.train()

# Modeli kaydet
trainer.save_model("./results")

# Modeli yükle
model = BertForSequenceClassification.from_pretrained("./results", num_labels=3)

from transformers import BertTokenizer, BertForSequenceClassification
import torch

# Model ve tokenizer'ı yükle
model_path = "./results"  # Eğitilen modelin kaydedildiği dizin
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertForSequenceClassification.from_pretrained(model_path)

# Sınıf isimleri
class_names = ["Hate Speech", "Offensive", "Neither"]

def classify_text(text):
    """
    Verilen metni sınıflandırır ve detaylı sonuç döndürür.

    Args:
        text (str): Analiz edilecek metin

    Returns:
        dict: {
            'prediction': str (tahmin edilen sınıf),
            'confidence': float (tahmin güven skoru),
            'probabilities': dict (tüm sınıfların olasılıkları),
            'raw_output': list (modelin ham çıktıları)
        }
    """
    # Tokenization
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=128
    )

    # Model ile tahmin yap
    with torch.no_grad():
        outputs = model(**inputs)

    # Olasılıkları hesapla
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    confidence, predicted_idx = torch.max(probs, dim=-1)

    # Sonuçları formatla
    result = {
        'prediction': class_names[predicted_idx],
        'confidence': confidence.item(),
        'probabilities': {
            class_names[i]: round(probs[0][i].item(), 4) for i in range(len(class_names))
        },
        'raw_output': outputs.logits.tolist()[0]
    }

    return result

# Kullanım örnekleri
sample_texts = [
    "I love this place! The staff is amazing!",
    "You're so stupid, I can't believe you did that",
    "All people from that country should be killed"
]

for text in sample_texts:
    print(f"\nMetin: '{text}'")
    result = classify_text(text)
    print(f"Tahmin: {result['prediction']} (%{result['confidence']*100:.2f})")
    print("Detaylar:")
    for cls, prob in result['probabilities'].items():
        print(f"  {cls}: {prob*100:.2f}%")
    print("---")



import torch
print(torch.__version__)
print("CUDA mevcut mu?", torch.cuda.is_available())

!pip install -U transformers

import os
os.kill(os.getpid(), 9)

import os
os.environ["WANDB_DISABLED"] = "true"  # wandb tamamen devre dışı
import torch
from torch import cuda
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments
from torch.utils.data import Dataset

# GPU kontrolü ve ayarları
device = 'cuda' if cuda.is_available() else 'cpu'
print(f"⚡ Kullanılan cihaz: {device}")
print(f"🔍 GPU Detay: {torch.cuda.get_device_name(0) if cuda.is_available() else 'CPU kullanılıyor'}")

# Veri yükleme
df = pd.read_csv("context_aware_labeled_data.csv")
X = df['CONTEXT_INPUT'].tolist()  # İngilizce metinler
y = df['class'].tolist()
class_names = ["Hate Speech", "Offensive Language", "Neither"]

# Train/Test split (%80-%20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Özel Dataset sınıfı (GPU'ya otomatik yükleme)
class EnglishTweetDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.encodings = tokenizer(
            texts,
            truncation=True,
            padding='max_length',
            max_length=max_length,
            return_tensors="pt"
        )
        self.labels = torch.tensor(labels)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return {
            'input_ids': self.encodings['input_ids'][idx],         # .to(device) YOK
            'attention_mask': self.encodings['attention_mask'][idx],
            'labels': self.labels[idx]
        }

# RoBERTa tokenizer ve model
roberta_tokenizer = RobertaTokenizer.from_pretrained("roberta-base")
roberta_model = RobertaForSequenceClassification.from_pretrained(
    "roberta-base",
    num_labels=3
).to(device)

# Eğitim ayarları (İngilizce için optimize)
# Eğitim ayarları (eski versiyon transformers için sadeleştirilmiş)
training_args = TrainingArguments(
    output_dir="./results_roberta_en",
    per_device_train_batch_size=8,
    num_train_epochs=4,
    logging_dir="./logs_roberta_en"
)


# Trainer
trainer = Trainer(
    model=roberta_model,
    args=training_args,
    train_dataset=EnglishTweetDataset(X_train, y_train, roberta_tokenizer),
    eval_dataset=EnglishTweetDataset(X_test, y_test, roberta_tokenizer)
)

# Eğitimi başlat
print("🔥 RoBERTa modeli eğitiliyor...")
trainer.train()

# ⭐⭐⭐ BU SATIRLARI EKLEYİN ⭐⭐⭐
# Modeli ve tokenizer'ı kaydet
trainer.save_model("results_roberta_en")  # "./" olmadan
tokenizer.save_pretrained("results_roberta_en")

# Kaydedilen dosyaları kontrol et
print("\n💾 Kaydedilen model dosyaları:")
!ls -l results_roberta_en

# GPU belleğini temizle
torch.cuda.empty_cache()
print("✅ Eğitim tamamlandı ve model kaydedildi!")

# Test setinde değerlendirme
print("🧪 Model test ediliyor...")
test_results = trainer.predict(EnglishTweetDataset(X_test, y_test, roberta_tokenizer))
y_pred = torch.argmax(torch.tensor(test_results.predictions), dim=1).cpu().numpy()

# Detaylı metrikler
print("\n📊 RoBERTa Classification Report (Test Seti):")
print(classification_report(y_test, y_pred, target_names=class_names, digits=4))

# Confusion Matrix
plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap="Blues", values_format='d')
plt.title("RoBERTa - Confusion Matrix (İngilizce Veri)\n", fontsize=14, pad=20)
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("roberta_confusion_matrix_en.png", dpi=300)
plt.show()

import torch
from transformers import RobertaTokenizer, RobertaForSequenceClassification

# Model ve tokenizer yükleniyor
model_path = "results_roberta_en"  # Modelin kaydedildiği dizin
tokenizer = RobertaTokenizer.from_pretrained(model_path)
model = RobertaForSequenceClassification.from_pretrained(model_path)

# GPU'ya gönder (varsa)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Sınıf isimleri
class_names = ["Hate Speech", "Offensive Language", "Neither"]

def predict_text(text, confidence_threshold=0.7):
    """
    RoBERTa modeli ile metin sınıflandırma

    Args:
        text (str): Analiz edilecek metin
        confidence_threshold (float): Minimum güven skoru (0-1 arası)

    Returns:
        dict: {
            'prediction': str (tahmin edilen sınıf),
            'confidence': float (güven skoru),
            'probabilities': dict (tüm sınıf olasılıkları),
            'is_confident': bool (eşik değerini aşıyor mu)
        }
    """
    # Tokenizasyon
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=128
    ).to(device)

    # Tahmin
    with torch.no_grad():
        outputs = model(**inputs)

    # Olasılık hesaplama
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    confidence, pred_idx = torch.max(probs, dim=-1)

    # Sonuç formatlama
    return {
        'prediction': class_names[pred_idx],
        'confidence': round(confidence.item(), 4),
        'probabilities': {
            class_names[i]: round(prob.item(), 4) for i, prob in enumerate(probs[0])
        },
        'is_confident': confidence.item() >= confidence_threshold
    }

# Kullanım örneği
if __name__ == "__main__":
    test_texts = [
        "You're completely useless",
        "You're so stupid!",
        "This place is really nice and calm, and everyone is very friendly."
    ]

    for text in test_texts:
        result = predict_text(text)
        print(f"\n📝 Metin: {text[:50]}{'...' if len(text)>50 else ''}")
        print(f"🔮 Tahmin: {result['prediction']} (Güven: {result['confidence']*100:.1f}%)")
        print("📊 Olasılıklar:")
        for cls, prob in result['probabilities'].items():
            print(f"   - {cls}: {prob*100:.1f}%")
        if not result['is_confident']:
            print("⚠️ Düşük güven skoru - Sonuç belirsiz olabilir!")
        print("━"*50)



import torch
print(torch.__version__)
print("CUDA mevcut mu?", torch.cuda.is_available())

!pip install -U transformers

import os
os.kill(os.getpid(), 9)

import os
os.environ["WANDB_DISABLED"] = "true"  # wandb tamamen devre dışı
import torch
from torch import cuda
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments
from torch.utils.data import Dataset

# GPU kontrolü ve ayarları
device = 'cuda' if cuda.is_available() else 'cpu'
print(f"⚡ Kullanılan cihaz: {device}")
print(f"🔍 GPU Detay: {torch.cuda.get_device_name(0) if cuda.is_available() else 'CPU kullanılıyor'}")

# Veri yükleme
df = pd.read_csv("context_aware_labeled_data.csv")
X = df['CONTEXT_INPUT'].tolist()  # İngilizce metinler
y = df['class'].tolist()
class_names = ["Hate Speech", "Offensive Language", "Neither"]

# Train/Test split (%80-%20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Özel Dataset sınıfı (GPU'ya otomatik yükleme)
class EnglishTweetDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.encodings = tokenizer(
            texts,
            truncation=True,
            padding='max_length',
            max_length=max_length,
            return_tensors="pt"
        )
        self.labels = torch.tensor(labels)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return {
            'input_ids': self.encodings['input_ids'][idx],         # .to(device) YOK
            'attention_mask': self.encodings['attention_mask'][idx],
            'labels': self.labels[idx]
        }

# RoBERTa tokenizer ve model
roberta_tokenizer = RobertaTokenizer.from_pretrained("roberta-base")
roberta_model = RobertaForSequenceClassification.from_pretrained(
    "roberta-base",
    num_labels=3
).to(device)

# Eğitim ayarları (İngilizce için optimize)
# Eğitim ayarları (eski versiyon transformers için sadeleştirilmiş)
training_args = TrainingArguments(
    output_dir="./results_roberta_en",
    per_device_train_batch_size=8,
    num_train_epochs=4,
    logging_dir="./logs_roberta_en"
)


# Trainer
trainer = Trainer(
    model=roberta_model,
    args=training_args,
    train_dataset=EnglishTweetDataset(X_train, y_train, roberta_tokenizer),
    eval_dataset=EnglishTweetDataset(X_test, y_test, roberta_tokenizer)
)

# Eğitimi başlat
print("🔥 RoBERTa modeli eğitiliyor...")
trainer.train()

# ⭐⭐⭐ BU SATIRLARI EKLEYİN ⭐⭐⭐
# Modeli ve tokenizer'ı kaydet
trainer.save_model("results_roberta_en")  # "./" olmadan
tokenizer.save_pretrained("results_roberta_en")

# Kaydedilen dosyaları kontrol et
print("\n💾 Kaydedilen model dosyaları:")
!ls -l results_roberta_en

# GPU belleğini temizle
torch.cuda.empty_cache()
print("✅ Eğitim tamamlandı ve model kaydedildi!")

# Test setinde değerlendirme
print("🧪 Model test ediliyor...")
test_results = trainer.predict(EnglishTweetDataset(X_test, y_test, roberta_tokenizer))
y_pred = torch.argmax(torch.tensor(test_results.predictions), dim=1).cpu().numpy()

# Detaylı metrikler
print("\n📊 RoBERTa Classification Report (Test Seti):")
print(classification_report(y_test, y_pred, target_names=class_names, digits=4))

# Confusion Matrix
plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap="Blues", values_format='d')
plt.title("RoBERTa - Confusion Matrix (İngilizce Veri)\n", fontsize=14, pad=20)
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("roberta_confusion_matrix_en.png", dpi=300)
plt.show()

import torch
from transformers import RobertaTokenizer, RobertaForSequenceClassification

# Model ve tokenizer yükleniyor
model_path = "results_roberta_en"  # Modelin kaydedildiği dizin
tokenizer = RobertaTokenizer.from_pretrained(model_path)
model = RobertaForSequenceClassification.from_pretrained(model_path)

# GPU'ya gönder (varsa)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Sınıf isimleri
class_names = ["Hate Speech", "Offensive Language", "Neither"]

def predict_text(text, confidence_threshold=0.7):
    """
    RoBERTa modeli ile metin sınıflandırma

    Args:
        text (str): Analiz edilecek metin
        confidence_threshold (float): Minimum güven skoru (0-1 arası)

    Returns:
        dict: {
            'prediction': str (tahmin edilen sınıf),
            'confidence': float (güven skoru),
            'probabilities': dict (tüm sınıf olasılıkları),
            'is_confident': bool (eşik değerini aşıyor mu)
        }
    """
    # Tokenizasyon
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=128
    ).to(device)

    # Tahmin
    with torch.no_grad():
        outputs = model(**inputs)

    # Olasılık hesaplama
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    confidence, pred_idx = torch.max(probs, dim=-1)

    # Sonuç formatlama
    return {
        'prediction': class_names[pred_idx],
        'confidence': round(confidence.item(), 4),
        'probabilities': {
            class_names[i]: round(prob.item(), 4) for i, prob in enumerate(probs[0])
        },
        'is_confident': confidence.item() >= confidence_threshold
    }

# Kullanım örneği
if __name__ == "__main__":
    test_texts = [
        "You're completely useless",
        "You're so stupid!",
        "This place is really nice and calm, and everyone is very friendly."
    ]

    for text in test_texts:
        result = predict_text(text)
        print(f"\n📝 Metin: {text[:50]}{'...' if len(text)>50 else ''}")
        print(f"🔮 Tahmin: {result['prediction']} (Güven: {result['confidence']*100:.1f}%)")
        print("📊 Olasılıklar:")
        for cls, prob in result['probabilities'].items():
            print(f"   - {cls}: {prob*100:.1f}%")
        if not result['is_confident']:
            print("⚠️ Düşük güven skoru - Sonuç belirsiz olabilir!")
        print("━"*50)

!pip install transformers datasets --upgrade --quiet
!pip install -U transformers --quiet
!pip install matplotlib seaborn --quiet

# GPU kontrolü
import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Kullanılan cihaz: {device}")

# Gerekli kütüphaneler
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    classification_report,
    accuracy_score,
    confusion_matrix,
    precision_score,
    recall_score,
    f1_score
)
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import (
    XLMRobertaTokenizer,
    XLMRobertaForSequenceClassification,
    Trainer,
    TrainingArguments
)
from datasets import Dataset
import os

# Veri yükleme
try:
    df = pd.read_csv("context_aware_labeled_data.csv")
    print("Veri başarıyla yüklendi. Örnek veriler:")
    print(df.head())
except FileNotFoundError:
    print("HATA: 'context_aware_labeled_data.csv' dosyası bulunamadı.")
    exit()

# Veri hazırlığı
X = df['CONTEXT_INPUT']
y = df['class']

# Sınıf dağılımını kontrol et
print("\nSınıf Dağılımı:")
print(y.value_counts())

# Eğitim-test ayrımı
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    stratify=y,
    test_size=0.2,
    random_state=42
)
train_df = pd.DataFrame({'text': X_train, 'label': y_train})
test_df = pd.DataFrame({'text': X_test, 'label': y_test})

# Model ve tokenizer
model_name = "xlm-roberta-base"
try:
    tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)
    num_labels = len(df['class'].unique())
    print(f"\nModel yükleniyor: {model_name} (Etiket sayısı: {num_labels})")

    model = XLMRobertaForSequenceClassification.from_pretrained(
        model_name,
        num_labels=num_labels
    ).to(device)
except Exception as e:
    print(f"\nHATA: Model yüklenirken hata oluştu: {e}")
    exit()

# Tokenizasyon fonksiyonu
def tokenize_function(examples):
    return tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=256
    )

# Dataset oluşturma
try:
    print("\nVeri setleri hazırlanıyor...")
    train_dataset = Dataset.from_pandas(train_df)
    test_dataset = Dataset.from_pandas(test_df)

    train_dataset = train_dataset.map(tokenize_function, batched=True)
    test_dataset = test_dataset.map(tokenize_function, batched=True)

    train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
    test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
except Exception as e:
    print(f"\nHATA: Veri seti hazırlanırken hata oluştu: {e}")
    exit()

# Eğitim ayarları (GÜNCELLENMİŞ VERSİYON)
training_args = TrainingArguments(
    output_dir="./xlmr_results",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=16,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=100,
    eval_strategy="epoch",  # evaluation_strategy yerine eval_strategy
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    greater_is_better=True,
    disable_tqdm=False,
    no_cuda=not torch.cuda.is_available(),
    report_to="none",
    save_total_limit=2,
)

# Metrik hesaplama
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    if isinstance(predictions, tuple):
        predictions = predictions[0]
    predictions = np.argmax(predictions, axis=1)

    accuracy = accuracy_score(labels, predictions)
    precision = precision_score(labels, predictions, average='weighted')
    recall = recall_score(labels, predictions, average='weighted')
    f1 = f1_score(labels, predictions, average='weighted')

    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics,
)

# Eğitim
print("\nEğitim başlıyor...")
try:
    train_result = trainer.train()
    print("\nEğitim tamamlandı!")

    metrics = train_result.metrics
    print(f"\nEğitim Metrikleri:")
    print(f"- Toplam Eğitim Süresi: {metrics['train_runtime']:.2f} saniye")
    print(f"- Örnek başına süre: {metrics['train_samples_per_second']:.2f} örnek/saniye")
    print(f"- Kayıp: {metrics['train_loss']:.4f}")

except Exception as e:
    print(f"\nHATA: Eğitim sırasında hata oluştu: {e}")
    if "CUDA out of memory" in str(e):
        print("Bellek hatası! Batch boyutunu küçültmeyi deneyin.")
    exit()

# Değerlendirme
print("\nTest seti üzerinde değerlendirme yapılıyor...")
try:
    eval_results = trainer.evaluate()
    print("\nDeğerlendirme Sonuçları:")
    print(f"- Accuracy: {eval_results['eval_accuracy']:.4f}")
    print(f"- Precision: {eval_results['eval_precision']:.4f}")
    print(f"- Recall: {eval_results['eval_recall']:.4f}")
    print(f"- F1-Score: {eval_results['eval_f1']:.4f}")

except Exception as e:
    print(f"\nHATA: Değerlendirme sırasında hata oluştu: {e}")

# Tahminler ve detaylı analiz
print("\nTahminler yapılıyor ve detaylı analiz...")
try:
    predictions = trainer.predict(test_dataset)
    preds = np.argmax(predictions.predictions, axis=1)  # Düzeltme: predictions.predictions

    # Sınıf isimleri
    target_names = ["Hate Speech", "Offensive Language", "Neither"]

    # Kapsamlı sınıflandırma raporu
    print("\n📊 Detaylı Sınıflandırma Raporu:")
    print(classification_report(
        y_test,
        preds,
        target_names=target_names,
        digits=4
    ))

    # Confusion Matrix
    cm = confusion_matrix(y_test, preds)
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        cm,
        annot=True,
        fmt='d',
        cmap='Blues',
        xticklabels=target_names,
        yticklabels=target_names
    )
    plt.title('Confusion Matrix', pad=20)
    plt.xlabel('Tahmin Edilen Sınıf')
    plt.ylabel('Gerçek Sınıf')
    plt.xticks(rotation=45)
    plt.yticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # Sınıf bazında metrikler
    print("\n🔍 Sınıf Bazında Performans:")
    for i, class_name in enumerate(target_names):
        print(f"\n{class_name}:")
        print(f"- Precision: {precision_score(y_test, preds, average=None)[i]:.4f}")
        print(f"- Recall: {recall_score(y_test, preds, average=None)[i]:.4f}")
        print(f"- F1-Score: {f1_score(y_test, preds, average=None)[i]:.4f}")

    # Örnek tahminler
    print("\n🎯 Örnek Tahminler:")
    sample_df = test_df.copy()
    sample_df['prediction'] = preds
    print(sample_df.sample(5, random_state=42))

except Exception as e:
    print(f"\nHATA: Tahminler sırasında hata oluştu: {e}")

# Model kaydetme
print("\nModel kaydediliyor...")
try:
    model.save_pretrained("./xlmr_final_model")
    tokenizer.save_pretrained("./xlmr_final_model")
    print("Model başarıyla kaydedildi: './xlmr_final_model' klasörüne")
except Exception as e:
    print(f"\nHATA: Model kaydedilirken hata oluştu: {e}")

# Son bilgiler
print("\nℹ️ Eğitim Bilgileri:")
print(f"- Toplam Eğitim Örnek Sayısı: {len(train_df)}")
print(f"- Toplam Test Örnek Sayısı: {len(test_df)}")
print(f"- Kullanılan Model: {model_name}")
print(f"- Eğitim Epoch Sayısı: {training_args.num_train_epochs}")
print(f"- Batch Boyutu (Eğitim): {training_args.per_device_train_batch_size}")
print(f"- Batch Boyutu (Değerlendirme): {training_args.per_device_eval_batch_size}")

import torch
import numpy as np
from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification

# Tokenizer ve model yükleme (Zaten yüklediğiniz model kullanılıyor)
tokenizer = XLMRobertaTokenizer.from_pretrained("xlm-roberta-base")
model = XLMRobertaForSequenceClassification.from_pretrained("xlm-roberta-base", num_labels=3).to(device)

# Sınıfların isimleri
class_names = ["Hate Speech", "Offensive Language", "Neither"]

# Loss fonksiyonuna ağırlık eklemek için her sınıf için ağırlık belirleyelim
class_weights = torch.tensor([1.0, 1.0, 2.0]).to(device)  # 'Neither' sınıfına daha fazla ağırlık veriyoruz

# Tokenization ve tahmin fonksiyonu
def predict(texts):
    # Tokenizasyon
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt", max_length=256).to(device)

    # Model tahminleri
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits

    # Softmax ile olasılık hesaplama
    probs = torch.nn.functional.softmax(logits, dim=-1)

    # Her bir metin için tahmin ve sınıf olasılıklarını elde et
    predictions = torch.argmax(probs, dim=-1)

    # Tahminleri sınıf isimlerine dönüştür
    predicted_classes = [class_names[prediction] for prediction in predictions]

    return predicted_classes, probs

# Örnek metinler
texts = [
    "God damn it!!",
    "I hate you!",
    "You're the worst!"
]

# Tahmin yapma
predictions, probs = predict(texts)

# Sonuçları yazdır
for text, prediction, prob in zip(texts, predictions, probs):
    print(f"Text: {text}")
    print(f"Predicted Class: {prediction}")
    print(f"Class Probabilities: {prob}\n")